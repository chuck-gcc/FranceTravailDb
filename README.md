# France Travail job for warehouse data

![Alt text](/doc/general_struct.png)


Cet outil permet dâ€™extraire les offres dâ€™emploi quotidiennes par dÃ©partement Ã  travers lâ€™API de France Travail.
Il est composÃ© de trois modules principaux :

+ Job Scraper â†’ collecte les annonces via lâ€™API (TypeScript).

+ Processing Machine â†’ traite et nettoie les donnÃ©es (Python).

+ SQLite Database â†’ stocke les annonces au format bytes.

ğŸ“‚ Structure des batchs

Les annonces, calibrÃ©es selon les restrictions de lâ€™API, sont stockÃ©es dans des fichiers JSON de la forme :

```
{
    "resultat": [
        {obj},
        {obj},
        {obj},
        {obj}
    ]
}
```

Chaque objet est contrÃ´lÃ© puis insÃ©rÃ© dans la base de donnÃ©es SQLite.

# ğŸš€ Installation & ExÃ©cution

## job_scrapper (TypeScript)


```bash
cd job_scrapper

```
Creer un fichier .env et renseigner les clÃ© api et scope

``` bash
CLIENT_ID=xxxxx
CLIENT_SECRET=xxxxx
SCOPES_API= o2dsoffre api_offresdemploiv2

```

``` bash

npm install
npm run dev

```

or 

``` makefile
    make data
```

## Processing Machine (Python)

``` bash

cd processing machine
python3 processing machine.py

```

or 

``` makefile
    make sort
```

# ğŸ› ï¸ Technologies utilisÃ©es

TypeScript / Node.js â†’ collecte et appels API

Python â†’ traitement et transformation des donnÃ©es

SQLite â†’ stockage local lÃ©ger et rapide